{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag Of Words\n",
    "\n",
    "The bag-of-words model is a simplifying representation used in natural language processing and information retrieval (IR). In this model, a text (such as a sentence or a document) is represented as the bag (multiset) of its words, disregarding grammar and even word order but keeping multiplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\"\"\"\n",
    "bag_of_words_calculate: caclulates bag of words for train\n",
    "                        and test dataframe column\n",
    "                        \n",
    "arguments:\n",
    "    train_df: pandas dataframe\n",
    "    test_df:  pandas dataframe\n",
    "    column:   string\n",
    "\"\"\"\n",
    "def bag_of_words_calculate(train_df, test_df, column):\n",
    "    count_vectorizer = CountVectorizer(max_df=1.0, min_df=1, max_features=300)\n",
    "    train_X_bow = count_vectorizer.fit_transform(train_df[column])\n",
    "    test_X_bow = count_vectorizer.transform(test_df[column])\n",
    "    return train_X_bow, test_X_bow\n",
    "\n",
    "\"\"\"\n",
    "bag_of_words_calculate_store: caclulates bag of words for train and test dataframe\n",
    "                              column and stores them as a new column\n",
    "                        \n",
    "arguments:\n",
    "    train_df: pandas dataframe\n",
    "    test_df:  pandas dataframe\n",
    "    column:   string\n",
    "\"\"\"\n",
    "def bag_of_words_calculate_store(train_df, test_df, column):\n",
    "    train_X_bow,test_X_bow = bag_of_words_calculate(train_df, test_df, column)\n",
    "    \n",
    "    vectors = list()\n",
    "    for v in train_X_bow.toarray():\n",
    "        vectors.append(v)\n",
    "\n",
    "    # save tf-idfs as a new column in the train dataframe\n",
    "    train_df[f\"bow_{column}\"] = pd.Series(vectors,index=train_df.index)\n",
    "    \n",
    "    vectors = list()\n",
    "    for v in test_X_bow.toarray():\n",
    "        vectors.append(v)\n",
    "\n",
    "    # save tf-idfs as a new column in the test dataframe\n",
    "    test_df[f\"bow_{column}\"] = pd.Series(vectors,index=test_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tf-idf\n",
    "\n",
    "In information retrieval, tf–idf or TFIDF, short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\"\"\"\n",
    "tf_idf_calculate: caclulates tf-idfs for train and test dataframe column\n",
    "                        \n",
    "arguments:\n",
    "    train_df: pandas dataframe\n",
    "    test_df:  pandas dataframe\n",
    "    column:   string\n",
    "\"\"\"\n",
    "def tf_idf_calculate(train_df, test_df, column):\n",
    "    tf_idf_vectorizer = TfidfVectorizer(max_df=1.0, min_df=1, max_features=300)\n",
    "    train_X_tf_idf = tf_idf_vectorizer.fit_transform(train_df[column])\n",
    "    test_X_tf_idf = tf_idf_vectorizer.transform(test_df[column])\n",
    "    return train_X_tf_idf, test_X_tf_idf\n",
    "\n",
    "\"\"\"\n",
    "tf_idf_calculate: caclulates tf-idfs for train and test dataframe column \n",
    "                  and stores them as a new column\n",
    "arguments:\n",
    "    train_df: pandas dataframe\n",
    "    test_df:  pandas dataframe\n",
    "    column:   string\n",
    "\"\"\"\n",
    "def tf_idf_calculate_store(train_df, test_df, column):\n",
    "    train_X_tf_idf, test_X_tf_idf = tf_idf_calculate(train_df, test_df, column)\n",
    "\n",
    "    vectors = list()\n",
    "    for v in train_X_tf_idf.toarray():\n",
    "        vectors.append(v)\n",
    "    # save tf-idfs as a new column in the train dataframe\n",
    "    train_df[f\"tf_idf_{column}\"] = pd.Series(vectors, index = train_df.index)\n",
    "    \n",
    "    vectors = list()\n",
    "    for v in test_X_tf_idf.toarray():\n",
    "        vectors.append(v)\n",
    "    # save tf-idfs as a new column in the test dataframe\n",
    "    test_df[f\"tf_idf_{column}\"] = pd.Series(vectors, index = test_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2vec\n",
    "\n",
    "Word2Vec is one of the popular methods in language modeling and feature learning techniques in natural language processing (NLP). This method is used to create word embeddings in machine learning whenever we need vector representation of data.\n",
    "\n",
    "The advantage of using Word2Vec is that it can capture the distance between individual words.\n",
    "\n",
    "Word embeddings (for example word2vec) allow to exploit ordering of the words and semantics information from the text corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "\"\"\"\n",
    "word2vec_train: creates and trains a word2vec model for a dataframe column.\n",
    "                also, it can save the model\n",
    "\n",
    "arguments:\n",
    "    dataframe: pandas dataframe\n",
    "    column:    string\n",
    "\"\"\"\n",
    "def word2vec_create_train(dataframe, column, word2vec_model_file = None):\n",
    "    word2vec_model = Word2Vec(dataframe[column], size = 300, window = 5,\n",
    "                              min_count = 100, sg = 1, hs = 0, negative = 10)\n",
    "    word2vec_model.train(dataframe[column],total_examples=len(dataframe[column]),epochs=20)\n",
    "    if word2vec_model_file is not None:\n",
    "        word2vec_model.save(word2vec_model_file)\n",
    "    return word2vec_model\n",
    "\n",
    "\"\"\"\n",
    "word2vec_sentence_vectorizer: calculates the average of all word embeddings for \n",
    "                              each sentence and and stores them as a new column\n",
    "\n",
    "arguments:\n",
    "    dataframe: pandas dataframe\n",
    "    column:    string\n",
    "\"\"\"\n",
    "def word2vec_sentence_vectorizer(dataframe, column, word2vec_model, store = False):\n",
    "    sentences = dataframe[column].tolist()\n",
    "    vectors = list()\n",
    "    # for each sentence we sum all word embedding of each word\n",
    "    # and we divide by the number of all words in the sentence.\n",
    "    for sentence in sentences:\n",
    "        sentence_vector = list()\n",
    "        number_of_words = 0\n",
    "        for word in sentence:\n",
    "            try:\n",
    "                if number_of_words == 0:\n",
    "                    sentence_vector = word2vec_model[word]\n",
    "                else:\n",
    "                    sentence_vector = np.add(sentence_vector, word2vec_model[word])\n",
    "                number_of_words += 1\n",
    "            except:\n",
    "                pass\n",
    "        sentence_vector_array = np.asarray(sentence_vector) / number_of_words\n",
    "        vectors.append(sentence_vector_array)\n",
    "        \n",
    "    # save word2vecs as a new column in the dataframe\n",
    "    if store is True:\n",
    "        dataframe[f\"word2vec_{column}\"] = pd.Series(vectors, index = test_df.index)\n",
    "        \n",
    "    return vectors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
